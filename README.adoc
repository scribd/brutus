ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]
:toc: macro

= Brutus

An API for performing brute force vector search backed by pre-computed data in
S3. Optimised for a large number of small indexes

== Why ?

Most existing vector search engines work by pre-indexing (compuationally expensive) data and storing these indexes in memory, this operation is optimised towards a small number of very large vector spaces. Brutus is different, it does no pre-indexing and generates all indexes at runtime. Thefore, Brutus is optimised to use cases when you have a very large number of small indexes. Pre-indexing is compuationally expensive but also only works well for large indexes. This precomuting redcues runtime complexity at the trade for indexing but this strategy only works well when there are a small number of vector spaces. When you have a large number of vector spaces you are better generating vectors at runtime


== Development

This project uses Rust, so builds and tests can be done with:

* `cargo build`
* `cargo test`
* _etc_

Optionally for hot-reloading of the service during development:

[source,bash]
----
cargo install cargo-watch catflap
----

=== Testing against localstack

[source,bash]
----
cargo test --feature integration
----


To run the hot-reloading webserver:

[source,bash]
----
./scripts/live-reload
----

You can then open link:http://localhost:5000[localhost:5000]


=== Data file schema

chunk_id:long
chunk_text:string
chunk_embedding:array
element:float
page:integer
doc_id:long
chunk_sequence:integer
